experiment_name: "all_mip164"
output_base_dir: "runs"
augmentation: null
training:
  images_dir: "dat/training_data/images"
  labels_dir: "dat/training_data/labels"
  model_type: "vit_b_lm"
  patch_shape: [512, 512]
  batch_size: 4  # Increased from 2 to better utilize A40 GPU
  n_epochs: 100  # Increased from 50 since epochs will be faster
  n_samples: 16  # Set explicit value (was null/auto ~16) for more patches
  num_workers: 4  # NEW: Parallel data loading to eliminate bottleneck
  learning_rate: 1.0e-05  # Adjusted for batch_size=4 (2 * sqrt(4) * 1e-5)
  val_split: 0.1
  shuffle_data: true
  shuffle_seed: 42
  train_instance_segmentation_only: true
  use_min_instance_sampler: true
  min_instances_per_patch: 1
  checkpoint_name: "all_mip164"
  resume_from_checkpoint: null
  export_path: "final_models/all_mip164_model.pth"
